# 동기화
동기화를 통해 복제 셋에 동일한 데이터 복사본을 유지
- 기본 작업이 수행하는 모든 쓰기(CUD)를 포함하는 작업로그(`oplog`)를 유지
  - 프라이머리의 `local` 데이터베이스에 있는 `oplog.rs` 컬렉션에 저장  
  <img width="425" alt="mongodb_replica-insert_test_data" src="https://user-images.githubusercontent.com/17218212/157004468-93ab12a7-5750-4c0c-8671-2cd981248908.png">  
  <img width="1664" alt="mongodb_replica-oplog" src="https://user-images.githubusercontent.com/17218212/157004602-e94ef11e-b255-49c5-8459-947f94a2b9a1.png">  
  - 세컨더리는 복제할 작업에 대해 이 컬렉션을 조회
  ```javascript
  use local
  db.oplog.rs.find({ns:"test.test"}));
  // ns 는 컬렉션.데이터베이스로 이루어진 키
  ```
- 각 세컨더리는 자체 `oplog`를 유지/관리하고 프라이머리에서 복제하는 각 작업을 기록(세컨더리의 `local` 데이터베이스에 저장)
  - 작업 적용이 실패하면 세컨더리가 종료된다
  - 세컨더리가 다운되면 재시작 시 `oplog`의 마지막 작업을 기준으로 동기화 시작
  - `oplog` 의 작업을 동기화(재실행)하는 것은 멱등성을 가진다

> local 데이터베이스는 시스템 데이터베이스지만, 사용자가 local 데이터베이스 내에 컬렉션을 생성할 수도 있다. 따라서, 세컨더리가 복제하지 않아야 될 데이터를 local 데이터베이스 내에 커스텀하게 저장할 수 있다

## oplog
- oplog 는 local 데이터베이스에 저장되는 Cap 컬렉션(Capped Collection)
  - Cap 컬렉션은 `Tailable Cursor`를 이용해서 oplog에 기록되는 내용을 조회하며 모든 데이터의 변경을 추적할 수 있다
    - `Tailable Cursor`를 이용해서 특정 컬렉션의 변경 내용을 외부로 전달할 수 있다
    - `Change Streams` 를 이용해서 더 쉽게 변경 추적 가능 [참고](https://docs.mongodb.com/manual/changeStreams/)
- 기본적으로 고정된 크기로 특정 수의 작업만 보유 가능
- 데이터를 쓰는 속도와 거의 같은 속도로 `oplog`가 기록됨
  - 단, 삭제는 데이터를 지우기 때문에, `oplog`만 기록
- `oplog` 사이즈가 커야 하는 경우
  - 한 번에 여러 문서 업데이트 => 멱등성 유지를 위해 `oplog`는 도큐먼트마다 생김
  - 삽입한만큼 삭제하는 경우
  - 도큐먼트 업데이트가 잦은 경우
- 레플리카 셋 구성시 `oplogSizeMB` 옵션으로 사이즈를 지정할 수 있다
- 이미 레플리카 셋이 구성되어 있다면 직접 레플라키 셋 멤버에 접근하여 수정해야 한다 [참고](https://docs.mongodb.com/manual/tutorial/change-oplog-size/)
  ```javascript
  // 세컨더리 쉘 접속 후
  // local db 사용
  use local
  // 현재 oplog 사이즈 확인
  db.oplog.rs.stats().maxSize
  // 변경 (예제는 16000MB)
  db.adminCommand({replSetResizeOplog:1, size:Double(16000)})
  ```

### oplog 필드
- `ts(Timestamp)` : oplog 저장 순서를 결정하는 타임스탬프 값
- `t(Primary Term)` : MongoDB 레플리카 셋의 프라이머리를 선출하는 투표가 실행될 때마다 증가하는 값
- `h(Hash)` : oplog 저장시 실행된 작업에 대해 oplog hash 값을 이용하여 식별자를 할당
- `v(Version)` : oplog 도큐먼트 버전, 기본적으로 2 사용
- `op(Operation Type)` : 오퍼레이션 종류를 저장
  - `i` : insert
  - `d` : delete
  - `u` : update
  - `c` : command - 데이터베이스나 컬렉션의 생성/삭제, 컬렉션의 속성 변경
  - `n` : no operation - 단순 정보성 메시지 저장
- `ns(Namespace)` : 데이터가 변경된 대상 컬렉션의 네임스페이스(데이터베이스 이름과 컬렉션의 이름 조합)
  - operation type 이 command => `db_name.$cmmd`, no operation => 빈값(empty string)
- `o(Operation)` : 실제 변경된 정보 저장
- `o2(Operation 2)` : op 필드가 u 인 경우에만 존재, 업데이트 될 대상 도큐먼트의 프라이머리 키인 `_id` 필드의 정보 저장

## 초기 동기화(Initial Sync)
레플리카 셋의 한 구성원에서 다른 구성원으로 모든 데이터를 복사

### 수동 초기 동기화
데이터 파일을 수동으로 복사하고 초기동기화 수행(부트스트랩)
1. 데이터 파일 복사
2. MongoDB 서버 시작

> 수동 초기화시에는 반드시 레플리카 셋의 멤버 중에서 최소 하나이상의 멤버는 백업된 시점의 oplog를 가지고 있어야 함

### 자동 초기 동기화
1. `local` 데이터베이스를 제외한 모든 데이터베이스 복제
2. `mongod`는 대상 멤버에게 복사할 데이터베이스의 모든 컬렉션과 데이터를 검색
3. 대상 멤버의 모든 데이터를 삭제
4. 데이터 복제
5. `mongod`는 복사 중 발생한 데이터에 대한 변경사항에 대한 `oplog`를 사용하여 대상 멤버에 적용
6. 인덱스 생성

> 백업에서 복원하여 초기화 하는 것이 속도가 더 빠름

## Replication
세컨더리는 초기화 후 지속적으로 데이터를 복제한다  
동기화 소스에서 `oplog`를 복사하고 비동기 프로세스에서 적용  
최종일관성(eventual consistency)를 지킨다 => 프라이머리와 세컨더리의 데이터가 언젠가는 동기화 됨

![oplog-replication](https://user-images.githubusercontent.com/17218212/157004692-1ee5cdaf-1f6b-4975-ad82-475aa13e4e9f.png)  

- `oplog.rs` 컬렉션은 큐 형태로 데이터가 저장, 조회도 큐와 동일한 형태로 처리
- `Tailable cursor` : 리눅스의 `tail` 명령과 비슷하게 작동하는 커서
- 작동원리
  - 세컨더리 멤버의 oplog 수집을 위한 백그라운드 쓰레드(Observer)는 복제 소스(동기화 원본 멤버)로부터 oplog를 가져와서 로컬 MongoDB의 메모리 큐에 저장
  - 레플리케이션 배치 쓰레드는 큐에서 일정 개수의 oplog를 가져와서 oplog 적용 쓰레드 개수에 맞게 작업량을 나눈 후 oplog 적용 쓰레드에게 작업 요청 [oplog 적용 쓰레드 개수 조절](https://docs.mongodb.com/manual/reference/parameters/#mongodb-parameter-param.replWriterMinThreadCount)
- 글로벌 쓰기 잠금
  - oplog 적용 쓰레드는 각자 자신에게 부여된 oplog 이벤트를 서로 간섭없이 실행
  - oplog 적용 쓰레드가 실제 작업을 처리하기 직전에 레플리케이션 배치 쓰레드는 사용자의 쿼리 요청을 처리하지 못하도록 글로벌 쓰기 잠금을 건다
  - oplog 이벤트가 모두 처리되면 글로벌 쓰기 잠금을 해제
  - 세컨더리 멤버에서 글로벌 쓰기 잠금이 걸리면 읽기 쿼리가 처리되지 못하고 잠금해제를 기다려야 함
    - 세컨더리 멤버의 읽기 일관성을 위함
- 일정단위의 oplog 적용이 완료되면 세컨더리는 프라이머리에게 자신이 oplog를 어디까지 처리했는 지 알린다

### 세컨더리 멤버의 읽기 일관성
세컨더리 멤버에서 oplog 재생 시 사용자 쿼리를 블로킹하는데, 이것은 프라이머리에서 나타날 수 없는 상태가 세컨더리에서는 나타날 수 있기 때문이다  
세컨더리 멤버의 복제 쓰레드는 프라이머리의 oplog를 가져와서 다시 멀티쓰레드로 실행하는 데, 이것이 프라이머리에서 실행된 순서대로 실행되도록 보장하지 않기 때문이다

## 실효처리
- 세컨더리가 동기화 소스에서 수행되는 실제 작업보다 너무 뒤떨어지면, 세컨더리는 `stale`상태가 됨
  - 동기화 소스의 `oplog`에 있는 작업과 세컨더리의 작업이 너무 차이나면 모든 오퍼레이션을 수행하며 따라 잡을 수가 없어서 작업을 누락시킬 수 있음
- 세컨더리가 `stale`상태가 되었을 때 레플리카 셋의 각 구성원에서 차례로 복제를 시도하여 부트스트랩 => 가장 긴 `oplog`를 찾음
  - 충분히 긴 `oplog`를 가진 멤버가 없으면 복제를 중지하고 완전히 재동기화해야함
- `stale`상태를 피하려면 `oplog`사이즈를 충분히 크게 만들면 된다
  - `oplog`사이즈가 크더라도 `oplog`를 자주 사용할 일이 적기 때문에 메모리에 잘 올리지 않아 메모리 효율을 떨어뜨릴 가능성은 적다
  - 2~3일 동안의 정상작업에 대해 저장하는 것이 좋다

# Heartbeats
다른 멤버의 상태를 알기 위해 전송하는 신호 : 프라이머리 멤버, 동기화 가능 멤버, 다운된 멤버 확인
- 2초에 한번 다른 멤버에게 모두 전송
- 프라이머리가 복제셋의 과반수 이상의 멤버와 연결되지 않는 지 확인 => 과반수 이상과 연결되지 않으면 세컨더리로 강등 시킴

## 멤버 상태
기본적으로 프라이머리와 세컨더리로 나눌 수 있지만, 그 외에 자주 볼 수 있는 상태가 있음
- STARTUP : 처음 시작시 레플리카 셋 구성정보를 로딩 중인 상태, 구성정보가 로드되면 `STARTUP2` 상태로 변경
- STARTUP2 : 초기 동기화 프로세스동안 지속되는 상태, 복제 및 선출을 처리하기 위해 여러 개의 프로세스로 분기한 다음 `RECOVERING` 상태로 변경
- RECOVERING : 멤버가 정상작동 하지만 읽기 작업을 처리할 수 없는 상태
  - 세컨더리가 되기 전에 유효한 상태인지 확인하기 위해 이 상태를 거침
  - 조각모음(`compacting`)과 같이 오래걸리는 작업을 수행할 때나 `replSetMaintenance` 명령의 결과로 이 상태가 될 수 있음
  - 멤버가 다른 멤버들보다 많이 뒤처질 때 따라잡기 위해 이 상태가 될 수 있음
- [ARBITER](https://github.com/pch8388/pch8388.github.io/blob/master/docs/read-book/%EB%AA%BD%EA%B3%A0DB%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/10.%EB%B3%B5%EC%A0%9C%20%EC%85%8B%20%EC%84%A4%EC%A0%95.md#%EC%95%84%EB%B9%84%ED%84%B0-%EC%84%A0%EC%B6%9C) : 프라이머리 선출에 참여하는 용도로만 사용

시스템에 문제가 생긴 것을 알리는 상태
- DOWN : 멤버가 작동 중이었으나 연결할 수 없게 된 상태 => 네트워크 문제
- UNKNOWN : 멤버가 다른 멤버에 도달한 적이 없어 상태를 알 수 없음
- REMOVED : 레플리카 셋에서 멤버가 제거됨
- ROLLBACK : 멤버가 데이터를 롤백할 경우

## 프라이머리 선출 방법
- 세컨더리가 스스로 프라이머리가 될 것을 요청하는 데, 아래의 항목을 토대로 검사 수행
  - 요청받은 멤버가 프라이머리에 도달할 수 있는지
  - 선출되고자 하는 멤버의 복제 데이터가 최신인지
  - 다른 우선순위(priority)가 더 높은 멤버가 없는지
- 선출과정
  1. 복제 셋 멤버는 2초바다 하트비트(heartbeat, ping)을 보냄
  2. 10초 이내에 멤버가 하트비트를 보내지 않으면 다른 멤버가 해당 멤버를 접근할 수 없는 걸로 표시
  3. 선출 알고리즘은 우선순위가 가장 높은 세컨더리가 선출을 호출할 수 있도록 노력(?)
  4. 우선순위가 더 낮은 세컨더리가 프라이머리가 잠시 될 수 있지만 가장 우선순위가 높은 세컨더리가 프라이머리가 될 때까지 계속해서 과정을 반복
- 프라이머리로 선출되려면 복제데이터가 최신이어야 함
  - OpLog의 마지막 시간(lastOpTime)을 체크하여 동기화가 다 된것을 확인하고 선출된다 
- 프라이머리 멤버 선출에 참여할 수 있는 레플리카 셋의 멤버는 7개까지만 가능
  - 레플리카 셋에 더 많은 멤버를 참여 시킬 수 있지만 프라이머리 선출 과정에 드는 리소스를 줄이기 위해 7개까지만 참여시킴
  - 레플리카 셋 멤버가 7개를 초과하면 이후에 추가되는 멤버들은 Non-Voting 멤버여야 한다
- 스플릿 브레인(Split-brain) : 멤버 간에 네트워크 연결이 끊어졌지만 프라이머리는 여전히 정상상태여서 사용자의 요청을 처리하는 현상
  - 스플릿 브레인을 막기 위해 전체의 과반수 멤버와 통신이 되지 않으면 자동으로 프라이머리에서 세컨더리 멤버로 강등
  - 이러한 현상때문에 자가선출(Self-Election) 방법을 채택

### 세컨더리가 프라이머리를 투표할 때 고려하는 점
- 후보가 현재 투표자와 같은 레플리카 셋 멤버인지
- 후보의 우선순위가 현재 레플리카 셋에 있는 다른 모든 멤버보다 높은지
- 후보가 요청한 투표의 텀(Term)에 투표자가 투표한적이 없는지
- 후보자가 요청한 투표의 텀(Term)이 투표자가 이제까지 참여한 투표의 텀보다 큰 값인지
- 후보자가 투표자보다 더 최신 데이터를 갖고 있거나 동등한 데이터를 갖고 있는지(OpLog의 OpTime이 더 최신이거나 같은지)

### 프라이머리 선출시 정족수(Quorum)
레플리카 셋의 각 멤버는 `votes` 옵션의 값으로 0 또는 1을 가질 수 있음  
`votes` 옵션이 0인 멤버는 `Non-Voting` 멤버로 프라이머리 선출 시 정족수를 판단하는 기준에 미포함  
투표권을 가진 멤버들 중 `PRIMARY, SECONDARY, RECOVERING, ARBITER, ROLLBACK` 상태를 가진 경우에만 투표 가능
- `STARTUP` : 데이터를 가지지 않은 세컨더리가 프라이머리로부터 초기 동기화를 수행하는 중인 멤버
- `Unreachable` : 하트비트 통신이 되지 않는 상태

### 롤백
레플리카 셋 멤버끼리 동기화하는 과정에서 이미 저장된 데이터를(디스크 영구기록 or 저널로그까지 기록) 다시 삭제하는 과정
- 롤백 과정을 거치면서 삭제되거나 변경된 도큐먼트들은 몽고디비 데이터 디렉터리의 `rollback` 디렉터리에 저장
  - 필요한 재처리 작업을 이를 통해 수행
