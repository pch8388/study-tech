# 카프카 커넥트
- 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션
- 특정한 작업 형태를 템플릿으로 만들어놓은 커넥터를 실행함으로써 반복 작업을 줄일 수 있다
- 소스 커넥터 : 프로듀서 역할
- 싱크 커넥터 : 컨슈머 역할
- 커넥터 생성 명령을 받으면 내부에 커넥터와 타스크 생성
  - 커넥터 : 태스크 관리
  - 태스크 : 커넥터에 종속되는 개념으로 실질적인 데이터 처리
- 파이프 라인 생성 시 converter, transform 기능 추가 가능
  - converter
    - 데이터 처리 전 스키마 변경을 도와줌
    - JsonConverter, StringConverter, ByteArrayConverter 지원
    - 커스텀 컨버터 작성해서 사용 가능
  - tranform
    - 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용
    - Cast, Drop, ExtractField 등 기본 제공

## 커넥트 실행 방법
- 단일 모드 커넥트 : 단일 애플리케이션으로 실행
  - 1개 프로세스만 실행
  - SPOF(Single Point Of Failure)가 될 가능성이 높음
- 분산 모드 커넥트 : 2대 이상의 서버에서 클러스터 형태로 운영
  - 단일 모드 커넥트 대비 안정하게 운영할 수 있음
  - 무중단 스케일 아웃 가능
- API 호출을 통해 커넥터의 정보를 조회할 수 있음
  - port : 8083
    |요청 메서드|호출 경로|설명|
    |--|--|--|
    |GET|/|실행 중인 커넥트 정보 확인|
    |GET|/connectors|실행 중인 커넥터 이름 확인|
    |POST|/connectors|새로운 커넥터 생성 요청|
    |GET|/connectors/{커넥터 이름}|실행 중인 커넥터 정보 확인|
    |GET|/connectors/{커넥터 이름}/config|실행 중인 커넥터 설정값 확인|
    |PUT|/connectors/{커넥터 이름}/config|실행 중인 커넥터 설정값 변경 요청|
    |GET|/connectors/{커넥터 이름}/status|실행 중인 커넥터 상태 확인|
    |POST|/connectors/{커넥터 이름}/restart|실행 중인 커넥터 재시작 요청|
    |PUT|/connectors/{커넥터 이름}/pause|커넥터 일시 중지 요청|
    |PUT|/connectors/{커넥터 이름}/resume|일시 중지된 커넥터 실행 요청|
    |DELETE|/connectors/{커넥터 이름|실행 중인 커넥터 종료|
    |GET|/connectors/{커넥터 이름}/tasks|실행 중인 커넥터의 태스크 정보 확인|
    |GET|/connectors/{커넥터 이름}/tasks/{태스크 아이디}/status|실행 중인 커넥터의 태스크 상태 확인|
    |POST|/connectors/{커넥터 이름}/tasks/{태스크 아이디}/restart|실행 중인 커넥터의 태스크 재시작 요청|
    |GET|/connectors/{커넥터 이름}/topics|커넥터별 연동된 토픽 정보 확인|
    |GET|/connector-plugins|커넥트에 존재하는 커넥터 플러그인 확인|
    |PUT|/connector-plugins/{커넥터 플러그인 이름}/config/validate|커넥터 생성 시 설정값 유효 여부 확인|

## 단일 모드 커넥트
커넥트 설정 : `config/connect-standalone.properteis` 에서 설정
- `offset.storage.file.filename`
  - 단일 모드 커넥트는 로컬 파일에 오프셋 정보 저장 => 설정에 값으로 넣는 위치의 파일로 지정
  - 오프셋 정보는 소스 커넥터 또는 싱크 커넥터가 데이터 처리 시점을 저장하기 위해 사용
- `offset.flush.interval.ms` : 태스크가 처리 완료한 오프셋을 커밋하는 주기 설정
- `plugin.path` : 플러그인 형태로 추가할 커넥터의 디렉터리 주소 입력

커넥터 설정 : `config/connect-file-source.properties` 에서 설정(파일 커넥터)
- `name` : 커넥터 이름 => 커넥트에서 유일해야 함
- `file` : 읽을 파일 위치 지정
- `topic` : 읽은 파일의 데이터를 저장할 토픽 이름 지정

단일 모드 실행
```bash
$ bin/connect-standalone.sh config/connect-standalone.properteis \
config/connect-file-source.properties
```

## 분산 모드 커넥트
- 2개 이상의 프로세스가 1개의 그룹으로 묶여서 운영
  - 1개의 커넥트 프로세스에 이슈가 발생하여 종료되어도 살아있는 나머지 1개 커넥트 프로세스가 커넥터를 이어받아서 파이프라인을 지속 실행

커넥트 설정 : `config/connect-distributed.properties` 에서 설정
- `group.id` : 다수의 커넥트 프로세스들을 묶을 그룹 이름 지정
- `offset.storage.topic`, `config.storage.topic`, `status.storage.topic` 
  - 분산 모드 커넥트는 카프카 내부 토픽에 오프셋 정보를 저장
  - replication factor 를 3보다 높은 값 설정하는 것을 추천

분산 모드 커넥트는 커넥트 설정파일만 있으면 된다. 커넥터는 커넥트가 실행된 이후에 API 를 통해 실행/중단/변경할 수 있기 때문이다
```bash
$ bin/connect-distributed.sh config/connect-distributed.properties
```

## 소스 커넥터
- 소스 애플리케이션이나 소스 파일로부터 데이터를 가져와 토픽을 넣는 역할
- 오픈 소스 커넥터를 사용하거나 직접 개발
  - 직접 개발하는 경우는 `SourceConnector` `SourceTask` 클래스를 사용하여 직접 소스 커넥트를 구현
  - 직접 구현한 소스 커넥터를 빌드하여 jar파일로 만들고 커넥트를 실행 시 플러그인으로 추가하여 사용할 수 있음
- connect-api 라이브러리를 추가해야 함
  ```
  dependecies {
      compile 'org.apache.kafka:connect-api:2.5.0'
  }
  ```
- `SourceConnector` : 태스크를 실행하기 전 커넥터 설정파일을 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의하는 데에 사용
- `SourceTask` : 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와서 토픽으로 데이터를 보내는 역할을 수행
  - 토픽에서 사용하는 오프셋이 아닌 자체적으로 사용하는 오프셋이 있음 => 파일 등을 어디까지 읽었는 지 저장

### 파일 소스 커넥터 구현
- 카프카 커넥터를 직접 개발하고 플러그인으로 커넥트에 추가할 때 주의할 점은 사용자가 직접 작성한 클래스뿐만 아니라 참조하는 라이브러리도 함께 빌드하여 jar로 압축하여야 함
- `AbstractConfig` : 이 클래스를 상속하여 설정값을 정의
- `SourceConnector` : 커넥터 정의를 위해 상속
- `SourceTask` : 실제로 데이터를 가져와 토픽에 데이터를 넣는 역할
  - 소스 태스크에서 중요한 점은 소스 파일로부터 읽고 토픽으로 보낸 지점을 기록하고 사용
  - `poll()` 메서드는 태스크가 시작한 이후 지속적으로 데이터를 가져오기 위해 반복적으로 호출되는 메서드
- 생성한 커넥터는 컨슈머나 프로듀서와 다르게 플러그인 형태로 동작하므로 커넥터 자체로 실행할 수 없고, jar 를 생성하고 커넥트 플러그인 디렉터리에 넣으면 된다. jar 파일을 커넥트 지정 플러그인 디렉터리에 넣은 이후에는 커넥트를 재시작해야 한다

## 싱크 커넥터
- 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할
- connect-api 라이브러리를 추가해야 함
  ```
  dependecies {
      compile 'org.apache.kafka:connect-api:2.5.0'
  }
- `SinkConnector` : 태스크를 실행하기 전에 사용자로부터 입력받은 설정값 초기화하고 어떤 태스크 클래스를 사용할 것인지 정의
- `SinkTask` : 실제로 데이터를 처리
  - `put()` : 싱크 애플리케이션 또는 싱크 파일에 저장할 데이터를 토픽에서 주기적으로 가져오는 메서드
  - `flush()` : `put()` 메서드를 통해 가져온 데이터를 일정 주기로 싱크 애플리케이션 또는 싱크 파일에 저장할 때 사용하는 로직

# 카프카 미러메이커2
- 서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션
- 토픽의 모든 것을 완전히 동일하게 복제할 필요가 있을 경우 사용
- 토픽의 데이터, 설정 복사
  - 파티션의 변화, 토픽 설정값의 변화 등도 동기화
- `config/connect-mirror-maker.properties` 설정 사용
- 기본값으로 5초마다 토픽의 설정값을 확인하고 동기화

## 지리적 복제(Geo-Replication)
### Active-standby 클러스터 운영
다른 데이터 센터에 클러스터를 대기 시킴으로써 재해에 대비

### Active-active 클러스터 운영
물리적으로 아주 멀리 떨어진 곳에 지역마다 데이터 센터를 운영하며 해당 지역에 필요한 데이터만 복제하여 사용

### Hub and spoke 클러스터 운영
카프카 클러스터의 데이터를 한개의 카프카 클러스터로 모아 데이터 레이크로 사용