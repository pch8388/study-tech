# 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체

## 데이터 저장, 전송
- 프로듀서로부터 전달된 데이터는 파일 시스템에 저장
- 파일 시스템 확인
  ```bash
  # config/server.properties 안의 log.dir 옵션에 정의한 디렉터리
  $ ls /tmp/kafka-logs
  ```
  - 결과로 파티션 갯수만큼 디렉토리가 생성된 것을 볼 수 있음
  - 특정 파티션의 디렉터리 안에는 log, index, timeindex 파일들이 존재
    - log : 메시지와 메타데이터 저장
    - index : 메시지의 오프셋을 인덱싱한 정보
    - timeindex : 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보
      > 카프카 0.10.0.0 버전 이후로 메시지에는 timestamp 값이 포함. timestamp 값은 브로커가 적재한 데이터를 삭제하거나 압축하는 데 사용 
- OS의 페이지 캐시 사용
  - 파일 시스템을 사용하기 때문에 페이지 캐시를 통해 메모리에서 IO를 하여 속도를 높일 수 있음
  - 페이지 캐시는 한번 읽은 파일을 메모리에 올려두는 형태인 데, 카프카는 특정 용량이나 시간에 도달하기 전까지 같은 파일에서 로그를 기록하기 때문에 이런 기능을 잘 쓸 수 있는 것 같음
  - 이런 특징으로 힙 메모리 사이즈를 크게 설정하지 않아도 됨

## 데이터 복제, 싱크
- 파티션 단위로 복제가 일어남
- 복제(replication) : 팔로워 파티션들은 리더 파티션의 오프셋과 자신의 오프셋을 비교하여 차이가 나면 리더로부터 데이터를 가져와서 자신에게 저장 (몽고디비와 유사한 것으로 보임)
- 토픽의 성질마다 복제 개수를 다르게 설정하여 운영하기도 함
  - 데이터의 정합성보다 처리 속도가 중요하면 1 ~ 2 => 데이터 유실 가능성 있음
  - 데이터 정합성이 매우 중요하면 3 이상 => 복제가 많이 발생하므로 성능 하락
- 카프카는 모든 팔로워에게 복제가 완료되어야만(커밋되어야지만) 해당 오프셋의 메시지를 읽을 수 있도록 한다
  - 데이터의 일관성을 위해
- ACK 통신을 제거하고, 통신 횟수를 최대한 줄였다
  - ACK 통신을 제거하였는 데도 불구하고 팔로워의 복제를 알 수 있는 이유는 팔로워가 데이터를 요청할 때 리더가 데이터와 함께 이전 데이터의 커밋 여부를 같이 전송하기 때문이다

### replication 동작 원리
팔로워가 리더에게 요청하는 pull 방식으로 동작
1. 팔로워가 리더에게 0 오프셋을 요청한다
2. 리더의 데이터를 가져간 팔로워가 자신에게 복제
3. 팔로워가 리더에게 1 오프셋을 요청한다
4. 리더는 1 오프셋 데이터를 주면서 0 오프셋이 커밋되었다고 알려준다
5. 팔로워도 0 오프셋에 대해 커밋 표시를 한다

## 컨트롤러
- 클러스터의 브로커 중 한 대가 컨트롤러
- 다른 브로커 상태 체크 + 브로커가 클러스터에서 빠질 경우 해당 브로커가 가지고 있는 리더 파티션을 재분배
- 컨트롤러 역할의 브로커에 장애가 발생하면 다른 브로커가 컨트롤러 역할 (주키퍼가 선택? [참고](https://jaceklaskowski.gitbooks.io/apache-kafka/content/kafka-feature-controller-election.html))

## 데이터 삭제
- 브로커만 데이터 삭제 가능
- 파일 단위(`log segment`) 삭제
  - 특정 데이터를 선정해서 삭제 불가능

## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋 커밋
- 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장

## 코디네이터(coordinator)
- 클러스터 내의 브로커 중 한대가 코디네이터 역할 수행
- 컨슈머 그룹의 상태를 체크 + 파티션을 컨슈머와 매칭되도록 분배
- rebalance : 파티션을 컨슈머로 재할당

## 주키퍼
- 주키퍼는 카프카의 메타데이터 관리
  - znode 를 이용해 카프카 메타데이터를 주키퍼에 기록
  - 브로커의 노드관리, 토픽관리, 컨트롤러 관리
- 카프카 서버에서 주키퍼 연결
  ```bash
  $ bin/zookeeper-shell.sh my-kafka:2181
  ```
  - 주키퍼 쉘을 통해 znode 조회/수정
    > znode 란 주키퍼에서 사용하는 데어터 저장 단위
- 주키퍼 옵션 정의 예제
  ```
  파이프라인용 카프카 클러스터 : zookeeper.connect=localshot:2181/pipeline
  실시간 추천용 카프카 클러스터 : zookeeper.connect=localshot:2181/recommend
  ```

# 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위, 1개 이상의 파티션 소유
  - 토픽 이름 변경을 지원하지 않으므로, 이름 변경을 위해서는 삭제 후 재생성 해야함
- 레코드 : 프로듀서가 보낸 데이터
- 파티션 : 카프카 병렬처리의 핵심. 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
  - 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량 증가
  - 자료구조의 큐와 유사한 구조 => 삭제는 하지 않음

# 레코드
- 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성
- 타임스탬프 : 브로커 기준 유닉스 시간으로 설정
  - 프로듀서가 레코드를 생성할 때 임의 생성 가능
  - 카프카 0.10.0.0 버전 이상에서만 타임스탬프 사용 가능
- 메시지 키 : 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 저장
  - 동일한 메시지 키라면 동일 파티션에 들어감
- 메시지 값을 직렬화/역직렬화 할때는 반드시 동일한 형태로 처리해야 함

# 카프카 클라이언트
## 프로듀서 API
프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신

### 키가 없는 메시지 전송
Kafka client library 를 사용하여 토픽에 메시지를 발행해본다

```java
@Slf4j
public class SimpleProducer {

  private final static String TOPIC_NAME = "test";
  private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

  public static void main(String[] args) {
    Properties configs = new Properties();
    configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
    configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

    String messageValue = "testMessage";
    ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
    producer.send(record);
    log.info("{}", record);

    producer.flush();
    producer.close();
  }
}
```
- `send` 호출은 즉각적으로 메시지를 발행하지 않고, 프로듀서 내부에 가지고 있다가 배치 형태로 묶어서 브로커에 전송 => `flush` 가 호출되면 전송함

### 프로듀서 중요개념
- 레코드의 타임스탬프는 브로커에 저장될 때 브로커 시간을 기준으로 설정
  - 필요에 따라 레코드 생성 시간 또는 그 이전/이후로 설정 가능
- KafkaProducer.send() -> 토픽의 어느 파티션으로 전송될 지 결정(ProducerRecord) -> accumulator 버퍼에 데이터가 쌓임 -> 배치로 묶어서 전송
  - 파티셔너 기본값 : DefaultPartitioner
  - 프로듀서 api 의 기본값 : UniformStickyPartitioner
  - 프로듀서 api 제공 파티션 : UniformStickyPartitioner, RoundRobinPartitioner
    - 공통점 : 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터 전송
    - RoundRobinPartitioner : 들어오는 대로 파티션을 순회하면서 전송
    - UniformStickyPartitioner : accumulator 에서 데이터가 배치로 모두 묶일 때까지 기다렸다가 배치로 묶인 데이터는 모두 동일한 파티션에 전송
      - 실제로는 `DefaultPartitioner` 내부에서 `StickyPartitionCache` 를 사용하는 `UniformStickyPartitioner` 의 구현과 동일하게 분기가 되어있다
        ```java
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
          if (keyBytes == null) {
            // key 가 없으면 UniformStickyPartitioner 의 구현과 동일하게 동작
            return stickyPartitionCache.partition(topic, cluster);
          } 
          List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
          int numPartitions = partitions.size();
          // hash the keyBytes to choose a partition
          return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
        ```
- Partitioner 인터페이스를 상속받은 사용자 정의 클래스에서 메시지 키 또는 메시지 값에 따른 파티션 로직 지정 가능
- 압축방식 지정 가능 : gzip, snappy, lz4, zstd

### 필수 옵션
- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름
- key.serializer : 레코드 메시지 키 직렬화 클래스
- value.serializer : 레코드 메시지 값 직렬화 클래스

### 선택 옵션
- acks : 브로커에 데이터가 정상 송신 되었는 지 확인. 0, 1, -1(all) 중 하나 선택
  - 기본값 : 1
  - 0 : 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부 상관없이 성공으로 판단
  - 1 : 파티션에 데이터가 저장되면 전송 성공으로 판단
  - -1(all) : `min.insync.replicas` 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공하는 것으로 판단
- buffer.memory : 배치 버퍼 메모리 (기본값 : 33554432 => 32MB)
- retries : 브로커로부터 에러를 전송 받았을 때 재전송 시도 횟수 (기본값 : 2147483647)
- batch.size : 배치로 전송할 레코드 최대 용량 (기본값 : 16384)
- linger.ms : 배치를 전송하기 전까지 기다리는 최소 시간 (기본값 : 0)
- partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스 (기본값 : DefaultPartitioner)
- enable.idempotence : 멱등성 프로듀서로 동작할지 여부 설정 (기본값 : false)
- transactional.id : 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을 지 여부 설정. 이 값을 설정하면 트랜잭션 프로듀서로 동작 (기본값 : null)

### 키가 있는 메시지 전송
```java
public static void main(String[] args) {
  KafkaProducer<String, String> producer = new KafkaProducer<>(PropertiesFactory.getProperties());

  // 인자만 잘 설정해주면 된다.
  ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "SC", "10");
  producer.send(record);
  log.info("{}", record);
  producer.flush();
  producer.close();
}
```
> 파티션을 직접 지정하고 싶다면 토픽 이름, 파티션 번호, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성. 파티션 번호는 토픽에 존재하는 번호로 설정

### 브로커 정상 전송 여부를 확인하는 프로듀서
동기 결과받기
```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
RecordMetadata metadata = producer.send(record).get();
log.info(metadata.toString());

// test 토픽, 0번 파티션, 1 오프셋으로 저장됨
// [main] INFO me.study.SyncCallbackProducer - test-0@4
```

비동기 결과받기
```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
log.info("{}", record);

producer.send(record, (metadata, e) -> {
  if (e != null) {
    log.error(e.getMessage(), e);
  } else {
    log.info(metadata.toString());
  }
});
```

- 비동기로 결과를 받을 경우 동기로 결과를 받는 경우보다 더 빠른 속도로 데이터를 추가 처리
- 순서가 중요한 경우 사용 불가
  - 비동기 결과가 오기전에 다음 데이터를 보내고, 이전에 보냈던 데이터가 실패하면 순서가 바뀔 수 있음

