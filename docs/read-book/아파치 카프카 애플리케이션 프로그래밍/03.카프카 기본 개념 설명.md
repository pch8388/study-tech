# 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체

## 데이터 저장, 전송
- 프로듀서로부터 전달된 데이터는 파일 시스템에 저장
- 파일 시스템 확인
  ```bash
  # config/server.properties 안의 log.dir 옵션에 정의한 디렉터리
  $ ls /tmp/kafka-logs
  ```
  - 결과로 파티션 갯수만큼 디렉토리가 생성된 것을 볼 수 있음
  - 특정 파티션의 디렉터리 안에는 log, index, timeindex 파일들이 존재
    - log : 메시지와 메타데이터 저장
    - index : 메시지의 오프셋을 인덱싱한 정보
    - timeindex : 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보
      > 카프카 0.10.0.0 버전 이후로 메시지에는 timestamp 값이 포함. timestamp 값은 브로커가 적재한 데이터를 삭제하거나 압축하는 데 사용 
- OS의 페이지 캐시 사용
  - 파일 시스템을 사용하기 때문에 페이지 캐시를 통해 메모리에서 IO를 하여 속도를 높일 수 있음
  - 페이지 캐시는 한번 읽은 파일을 메모리에 올려두는 형태인 데, 카프카는 특정 용량이나 시간에 도달하기 전까지 같은 파일에서 로그를 기록하기 때문에 이런 기능을 잘 쓸 수 있는 것 같음
  - 이런 특징으로 힙 메모리 사이즈를 크게 설정하지 않아도 됨

## 데이터 복제, 싱크
- 파티션 단위로 복제가 일어남
- 복제(replication) : 팔로워 파티션들은 리더 파티션의 오프셋과 자신의 오프셋을 비교하여 차이가 나면 리더로부터 데이터를 가져와서 자신에게 저장 (몽고디비와 유사한 것으로 보임)
- 토픽의 성질마다 복제 개수를 다르게 설정하여 운영하기도 함
  - 데이터의 정합성보다 처리 속도가 중요하면 1 ~ 2 => 데이터 유실 가능성 있음
  - 데이터 정합성이 매우 중요하면 3 이상 => 복제가 많이 발생하므로 성능 하락
- 카프카는 모든 팔로워에게 복제가 완료되어야만(커밋되어야지만) 해당 오프셋의 메시지를 읽을 수 있도록 한다
  - 데이터의 일관성을 위해
- ACK 통신을 제거하고, 통신 횟수를 최대한 줄였다
  - ACK 통신을 제거하였는 데도 불구하고 팔로워의 복제를 알 수 있는 이유는 팔로워가 데이터를 요청할 때 리더가 데이터와 함께 이전 데이터의 커밋 여부를 같이 전송하기 때문이다

### replication 동작 원리
팔로워가 리더에게 요청하는 pull 방식으로 동작
1. 팔로워가 리더에게 0 오프셋을 요청한다
2. 리더의 데이터를 가져간 팔로워가 자신에게 복제
3. 팔로워가 리더에게 1 오프셋을 요청한다
4. 리더는 1 오프셋 데이터를 주면서 0 오프셋이 커밋되었다고 알려준다
5. 팔로워도 0 오프셋에 대해 커밋 표시를 한다

## 컨트롤러
- 클러스터의 브로커 중 한 대가 컨트롤러
- 다른 브로커 상태 체크 + 브로커가 클러스터에서 빠질 경우 해당 브로커가 가지고 있는 리더 파티션을 재분배
- 컨트롤러 역할의 브로커에 장애가 발생하면 다른 브로커가 컨트롤러 역할 (주키퍼가 선택? [참고](https://jaceklaskowski.gitbooks.io/apache-kafka/content/kafka-feature-controller-election.html))

## 데이터 삭제
- 브로커만 데이터 삭제 가능
- 파일 단위(`log segment`) 삭제
  - 특정 데이터를 선정해서 삭제 불가능

## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋 커밋
- 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장

## 코디네이터(coordinator)
- 클러스터 내의 브로커 중 한대가 코디네이터 역할 수행
- 컨슈머 그룹의 상태를 체크 + 파티션을 컨슈머와 매칭되도록 분배
- rebalance : 파티션을 컨슈머로 재할당

## 주키퍼
- 주키퍼는 카프카의 메타데이터 관리
  - znode 를 이용해 카프카 메타데이터를 주키퍼에 기록
  - 브로커의 노드관리, 토픽관리, 컨트롤러 관리
- 카프카 서버에서 주키퍼 연결
  ```bash
  $ bin/zookeeper-shell.sh my-kafka:2181
  ```
  - 주키퍼 쉘을 통해 znode 조회/수정
    > znode 란 주키퍼에서 사용하는 데어터 저장 단위
- 주키퍼 옵션 정의 예제
  ```
  파이프라인용 카프카 클러스터 : zookeeper.connect=localshot:2181/pipeline
  실시간 추천용 카프카 클러스터 : zookeeper.connect=localshot:2181/recommend
  ```

# 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위, 1개 이상의 파티션 소유
  - 토픽 이름 변경을 지원하지 않으므로, 이름 변경을 위해서는 삭제 후 재생성 해야함
- 레코드 : 프로듀서가 보낸 데이터
- 파티션 : 카프카 병렬처리의 핵심. 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
  - 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량 증가
  - 자료구조의 큐와 유사한 구조 => 삭제는 하지 않음

# 레코드
- 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성
- 타임스탬프 : 브로커 기준 유닉스 시간으로 설정
  - 프로듀서가 레코드를 생성할 때 임의 생성 가능
  - 카프카 0.10.0.0 버전 이상에서만 타임스탬프 사용 가능
- 메시지 키 : 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 저장
  - 동일한 메시지 키라면 동일 파티션에 들어감
- 메시지 값을 직렬화/역직렬화 할때는 반드시 동일한 형태로 처리해야 함

# 카프카 클라이언트
## 프로듀서 API
프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신

### 프로듀서 프로젝트 생성
Kafka client library 를 사용하여 토픽에 메시지를 발행해본다

```java
@Slf4j
public class SimpleProducer {

  private final static String TOPIC_NAME = "test";
  private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

  public static void main(String[] args) {
    Properties configs = new Properties();
    configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
    configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

    String messageValue = "testMessage";
    ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
    producer.send(record);
    log.info("{}", record);

    producer.flush();
    producer.close();
  }
}
```
- `send` 호출은 즉각적으로 메시지를 발행하지 않고, 프로듀서 내부에 가지고 있다가 배치 형태로 묶어서 브로커에 전송 => `flush` 가 호출되면 전송함

