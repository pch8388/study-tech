# 카프카 브로커, 클러스터, 주키퍼
- 카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체

## 데이터 저장, 전송
- 프로듀서로부터 전달된 데이터는 파일 시스템에 저장
- 파일 시스템 확인
  ```bash
  # config/server.properties 안의 log.dir 옵션에 정의한 디렉터리
  $ ls /tmp/kafka-logs
  ```
  - 결과로 파티션 갯수만큼 디렉토리가 생성된 것을 볼 수 있음
  - 특정 파티션의 디렉터리 안에는 log, index, timeindex 파일들이 존재
    - log : 메시지와 메타데이터 저장
    - index : 메시지의 오프셋을 인덱싱한 정보
    - timeindex : 메시지에 포함된 timestamp 값을 기준으로 인덱싱한 정보
      > 카프카 0.10.0.0 버전 이후로 메시지에는 timestamp 값이 포함. timestamp 값은 브로커가 적재한 데이터를 삭제하거나 압축하는 데 사용 
- OS의 페이지 캐시 사용
  - 파일 시스템을 사용하기 때문에 페이지 캐시를 통해 메모리에서 IO를 하여 속도를 높일 수 있음
  - 페이지 캐시는 한번 읽은 파일을 메모리에 올려두는 형태인 데, 카프카는 특정 용량이나 시간에 도달하기 전까지 같은 파일에서 로그를 기록하기 때문에 이런 기능을 잘 쓸 수 있는 것 같음
  - 이런 특징으로 힙 메모리 사이즈를 크게 설정하지 않아도 됨

## 데이터 복제, 싱크
- 파티션 단위로 복제가 일어남
- 복제(replication) : 팔로워 파티션들은 리더 파티션의 오프셋과 자신의 오프셋을 비교하여 차이가 나면 리더로부터 데이터를 가져와서 자신에게 저장 (몽고디비와 유사한 것으로 보임)
- 토픽의 성질마다 복제 개수를 다르게 설정하여 운영하기도 함
  - 데이터의 정합성보다 처리 속도가 중요하면 1 ~ 2 => 데이터 유실 가능성 있음
  - 데이터 정합성이 매우 중요하면 3 이상 => 복제가 많이 발생하므로 성능 하락
- 카프카는 모든 팔로워에게 복제가 완료되어야만(커밋되어야지만) 해당 오프셋의 메시지를 읽을 수 있도록 한다
  - 데이터의 일관성을 위해
- ACK 통신을 제거하고, 통신 횟수를 최대한 줄였다
  - ACK 통신을 제거하였는 데도 불구하고 팔로워의 복제를 알 수 있는 이유는 팔로워가 데이터를 요청할 때 리더가 데이터와 함께 이전 데이터의 커밋 여부를 같이 전송하기 때문이다

### replication 동작 원리
팔로워가 리더에게 요청하는 pull 방식으로 동작
1. 팔로워가 리더에게 0 오프셋을 요청한다
2. 리더의 데이터를 가져간 팔로워가 자신에게 복제
3. 팔로워가 리더에게 1 오프셋을 요청한다
4. 리더는 1 오프셋 데이터를 주면서 0 오프셋이 커밋되었다고 알려준다
5. 팔로워도 0 오프셋에 대해 커밋 표시를 한다

## 컨트롤러
- 클러스터의 브로커 중 한 대가 컨트롤러
- 다른 브로커 상태 체크 + 브로커가 클러스터에서 빠질 경우 해당 브로커가 가지고 있는 리더 파티션을 재분배
- 컨트롤러 역할의 브로커에 장애가 발생하면 다른 브로커가 컨트롤러 역할 (주키퍼가 선택? [참고](https://jaceklaskowski.gitbooks.io/apache-kafka/content/kafka-feature-controller-election.html))

## 데이터 삭제
- 브로커만 데이터 삭제 가능
- 파일 단위(`log segment`) 삭제
  - 특정 데이터를 선정해서 삭제 불가능

## 컨슈머 오프셋 저장
- 컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋 커밋
- 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장

## 코디네이터(coordinator)
- 클러스터 내의 브로커 중 한대가 코디네이터 역할 수행
- 컨슈머 그룹의 상태를 체크 + 파티션을 컨슈머와 매칭되도록 분배
- rebalance : 파티션을 컨슈머로 재할당

## 주키퍼
- 주키퍼는 카프카의 메타데이터 관리
  - znode 를 이용해 카프카 메타데이터를 주키퍼에 기록
  - 브로커의 노드관리, 토픽관리, 컨트롤러 관리
- 카프카 서버에서 주키퍼 연결
  ```bash
  $ bin/zookeeper-shell.sh my-kafka:2181
  ```
  - 주키퍼 쉘을 통해 znode 조회/수정
    > znode 란 주키퍼에서 사용하는 데어터 저장 단위
- 주키퍼 옵션 정의 예제
  ```
  파이프라인용 카프카 클러스터 : zookeeper.connect=localshot:2181/pipeline
  실시간 추천용 카프카 클러스터 : zookeeper.connect=localshot:2181/recommend
  ```

# 토픽과 파티션
- 토픽 : 카프카에서 데이터를 구분하기 위해 사용하는 단위, 1개 이상의 파티션 소유
  - 토픽 이름 변경을 지원하지 않으므로, 이름 변경을 위해서는 삭제 후 재생성 해야함
- 레코드 : 프로듀서가 보낸 데이터
- 파티션 : 카프카 병렬처리의 핵심. 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭
  - 컨슈머 개수를 늘림과 동시에 파티션 개수도 늘리면 처리량 증가
  - 자료구조의 큐와 유사한 구조 => 삭제는 하지 않음

# 레코드
- 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성
- 타임스탬프 : 브로커 기준 유닉스 시간으로 설정
  - 프로듀서가 레코드를 생성할 때 임의 생성 가능
  - 카프카 0.10.0.0 버전 이상에서만 타임스탬프 사용 가능
- 메시지 키 : 토픽에 레코드를 전송할 때 메시지 키의 해시값을 토대로 파티션을 저장
  - 동일한 메시지 키라면 동일 파티션에 들어감
- 메시지 값을 직렬화/역직렬화 할때는 반드시 동일한 형태로 처리해야 함

# 카프카 클라이언트
## 프로듀서 API
프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신

### 키가 없는 메시지 전송
Kafka client library 를 사용하여 토픽에 메시지를 발행해본다

```java
@Slf4j
public class SimpleProducer {

  private final static String TOPIC_NAME = "test";
  private final static String BOOTSTRAP_SERVERS = "my-kafka:9092";

  public static void main(String[] args) {
    Properties configs = new Properties();
    configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
    configs.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
    configs.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

    KafkaProducer<String, String> producer = new KafkaProducer<>(configs);

    String messageValue = "testMessage";
    ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
    producer.send(record);
    log.info("{}", record);

    producer.flush();
    producer.close();
  }
}
```
- `send` 호출은 즉각적으로 메시지를 발행하지 않고, 프로듀서 내부에 가지고 있다가 배치 형태로 묶어서 브로커에 전송 => `flush` 가 호출되면 전송함

### 프로듀서 중요개념
- 레코드의 타임스탬프는 브로커에 저장될 때 브로커 시간을 기준으로 설정
  - 필요에 따라 레코드 생성 시간 또는 그 이전/이후로 설정 가능
- KafkaProducer.send() -> 토픽의 어느 파티션으로 전송될 지 결정(ProducerRecord) -> accumulator 버퍼에 데이터가 쌓임 -> 배치로 묶어서 전송
  - 파티셔너 기본값 : DefaultPartitioner
  - 프로듀서 api 의 기본값 : UniformStickyPartitioner
  - 프로듀서 api 제공 파티션 : UniformStickyPartitioner, RoundRobinPartitioner
    - 공통점 : 메시지 키가 있을 때는 메시지 키의 해시값과 파티션을 매칭하여 데이터 전송
    - RoundRobinPartitioner : 들어오는 대로 파티션을 순회하면서 전송
    - UniformStickyPartitioner : accumulator 에서 데이터가 배치로 모두 묶일 때까지 기다렸다가 배치로 묶인 데이터는 모두 동일한 파티션에 전송
      - 실제로는 `DefaultPartitioner` 내부에서 `StickyPartitionCache` 를 사용하는 `UniformStickyPartitioner` 의 구현과 동일하게 분기가 되어있다
        ```java
        public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
          if (keyBytes == null) {
            // key 가 없으면 UniformStickyPartitioner 의 구현과 동일하게 동작
            return stickyPartitionCache.partition(topic, cluster);
          } 
          List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
          int numPartitions = partitions.size();
          // hash the keyBytes to choose a partition
          return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
        ```
- Partitioner 인터페이스를 상속받은 사용자 정의 클래스에서 메시지 키 또는 메시지 값에 따른 파티션 로직 지정 가능
- 압축방식 지정 가능 : gzip, snappy, lz4, zstd

### 필수 옵션
- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름
- key.serializer : 레코드 메시지 키 직렬화 클래스
- value.serializer : 레코드 메시지 값 직렬화 클래스

### 선택 옵션
- acks : 브로커에 데이터가 정상 송신 되었는 지 확인. 0, 1, -1(all) 중 하나 선택
  - 기본값 : 1
  - 0 : 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부 상관없이 성공으로 판단
  - 1 : 파티션에 데이터가 저장되면 전송 성공으로 판단
  - -1(all) : `min.insync.replicas` 개수에 해당하는 리더 파티션과 팔로워 파티션에 데이터가 저장되면 성공하는 것으로 판단
- buffer.memory : 배치 버퍼 메모리 (기본값 : 33554432 => 32MB)
- retries : 브로커로부터 에러를 전송 받았을 때 재전송 시도 횟수 (기본값 : 2147483647)
- batch.size : 배치로 전송할 레코드 최대 용량 (기본값 : 16384)
- linger.ms : 배치를 전송하기 전까지 기다리는 최소 시간 (기본값 : 0)
- partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스 (기본값 : DefaultPartitioner)
- enable.idempotence : 멱등성 프로듀서로 동작할지 여부 설정 (기본값 : false)
- transactional.id : 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을 지 여부 설정. 이 값을 설정하면 트랜잭션 프로듀서로 동작 (기본값 : null)

### 키가 있는 메시지 전송
```java
public static void main(String[] args) {
  KafkaProducer<String, String> producer = new KafkaProducer<>(PropertiesFactory.getProperties());

  // 인자만 잘 설정해주면 된다.
  ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "SC", "10");
  producer.send(record);
  log.info("{}", record);
  producer.flush();
  producer.close();
}
```
> 파티션을 직접 지정하고 싶다면 토픽 이름, 파티션 번호, 메시지 키, 메시지 값을 순서대로 파라미터로 넣고 생성. 파티션 번호는 토픽에 존재하는 번호로 설정

### 브로커 정상 전송 여부를 확인하는 프로듀서
동기 결과받기
```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
RecordMetadata metadata = producer.send(record).get();
log.info(metadata.toString());

// test 토픽, 0번 파티션, 1 오프셋으로 저장됨
// [main] INFO me.study.SyncCallbackProducer - test-0@4
```

비동기 결과받기
```java
ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, messageValue);
log.info("{}", record);

producer.send(record, (metadata, e) -> {
  if (e != null) {
    log.error(e.getMessage(), e);
  } else {
    log.info(metadata.toString());
  }
});
```

- 비동기로 결과를 받을 경우 동기로 결과를 받는 경우보다 더 빠른 속도로 데이터를 추가 처리
- 순서가 중요한 경우 사용 불가
  - 비동기 결과가 오기전에 다음 데이터를 보내고, 이전에 보냈던 데이터가 실패하면 순서가 바뀔 수 있음

## 컨슈머 API
```java
@Slf4j
public class SimpleConsumer {
  private final static String TOPIC_NAME = "test";
  private final static String GROUP_ID = "test-group";

  public static void main(String[] args) {
    // configs.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); 컨슈머 그룹 이름 선언
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(PropertiesFactory.getProperties(GROUP_ID));
    consumer.subscribe(List.of(TOPIC_NAME));

    while (true) {
      ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
      for (ConsumerRecord<String, String> record : records) {
        log.info("{}", record);
      }
    }
  }
}
```

- 컨슈머 그룹 이름을 선언하여 컨슈머의 목적을 구분할 수 있음
  - 컨슈머 그룹을 기준으로 컨슈머 오프셋 관리
  - 컨슈머가 중단되거나 재시작 되어도 컨슈머 오프셋을 기준으로 이후 데이터 처리
  - 컨슈머 그룹을 선언하지 않으면 어느 그룹에도 속하지 않는 컨슈머로 동작

### 컨슈머 중요 개념
- 1개 이상의 컨슈머로 이루어진 컨슈머 그룹 운영
  - 각 컨슈머 그룹끼리 격리된 환경에서 안전하게 운영
  - 컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다
  - 컨슈머 그룹의 컨슈머는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 함 => 컨슈머가 파티션보다 많으면 유휴 컨슈머가 생긴다
- 토픽의 특정 파티션만 구독하는 컨슈머 운영
- `리밸런싱(rebalancing)` : 컨슈머 그룹 중 일부 컨슈머에 장애가 발생하면 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어간다
  - 컨슈머가 추가되거나, 컨슈머가 제외될 때 발생
  - 리밸런싱은 컨슈머가 데이터를 처리하는 도중 언제나 발생할 수 있음 => 대응 코드 작성 필요
- `그룹 조정자(group coordinator)` : 리밸런싱을 발동시키는 역할
  - 컨슈머 추가/삭제 감지
  - 브로커 중 한대가 역할을 수행
- `커밋(commit)` : 브로커로부터 데이터를 어디까지 가져갔는지 커밋을 통해 기록
  - 브로커 내부 토픽인 `__consumer_offsets` 에 기록
  - 컨슈머 동작 이상이 발생하여 `__consumer_offsets` 에 기록하지 못하면 데이터 처리 중복이 발생할 수 있음 => 컨슈머 애플리케이션이 검증 해야함
  - 오프셋 커밋은 컨슈머 애플리케이션에서 명시적/비명시적으로 수행할 수 있음
    - 기본 옵션 : `poll()` 메서드 수행될 때 일정 간격으로 오프셋 커밋 
      - `enable.auto.commit=true` : 비명시 오프셋 커밋
      - `auto.commit.interval.ms` 에 설정된 값 이상의 시간이 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋
      - 비명시 오프셋 커밋은 `poll()` 메서드 호출 이후 리밸런싱 또는 컨슈머 강제종료 발생 시 컨슈머가 처리하는 데이터가 중복되거나 유실될 수 있는 가능성이 있음
    - 데이터 중복이나 유실을 허용하지 않는 서비스라면 자동 커밋 사용하면 안됨
    - 명시적 오프셋 커밋 : `commitSync()` / `commitAsync()` 호출
      - `poll()` 메서드를 통해 반환된 레코드의 마지막 오프셋을 기준으로 커밋 수행
      - `commitSync()` : 순서를 보장하지만 항상 결과를 응답 받고 다음처리를 진행하기 대문에 컨슈머 처리량이 떨어질 수 있음
      - `commitAsync()` : 순서를 강력히 보장하지 않지만 컨슈머 처리량이 높아질 수 있음, 데이터 중복처리가 발생할 수 있음

### 필수 옵션
- bootstrap.servers : 컨슈머가 데이터를 가져올 대상 카프카 클러스터에 속한 브로커의 호스트 이름
- key.deserializer : 레코드의 메시지 키를 역직렬화하는 클래스 지정
- value.deserializer : 레코드의 메시지 값을 역직렬화하는 클래스 지정

### 선택 옵션
- group.id : 컨슈머 그룹 아이디 지정. `subscribe()` 메서드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야 함
- auto.offset.reset : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을 지 선택하는 옵션
  - 기본값 : latest
  - latest : 가장 높은(최근) 오프셋부터 읽기 시작
  - earliest : 가장 낮은(오래된) 오프셋부터 읽기 시작
  - none : 컨슈머 그룹이 커밋한 기록이 있는지 찾아보고 없으면 오류 반환, 있으면 기존 커밋 기록 이후부터 읽는다
- enable.auto.commit : 자동으로 커밋할지 수동으로 할지 결정 (기본값 : true)
- auto.commit.interval.ms : 자동 커밋일 경우 오프셋 커밋 간격 지정 (기본값 : 5000)
- max.poll.records : `poll()` 메서드를 통해 반환되는 레코드 개수 지정 (기본값 : 500)
- session.timeout.ms : 컨슈머가 브로커와 연결이 끊기는 최대 시간. 이 시간내에 heartbeat 를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱 시작 (기본값 : 10000)
- heartbeat.interval.ms : heartbit 를 전송하는 시간 간격 (기본값 : 3000)
- max.poll.interval.ms : `poll()` 메서드를 호출하는 간격의 최대 시간. `poll()` 메서드를 호출한 이후 데이터를 처리하는 데에 시간이 너무 많이 걸리는 경우 비정상으로 판단하고 리밸런싱 시작(기본값 : 300000)
- isolation.level : 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용
  - 기본값 : read_uncommitted
  - read_committed : 커밋이 완료된 레코드만 읽음
  - read_uncommitted : 커밋 여부와 관계없이 파티션에 있는 모든 레코드를 읽음

### 동기 오프셋 커밋
```java
public static void main(String[] args) {
  Properties configs = PropertiesFactory.getProperties(GROUP_ID);
  configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

  KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);
  consumer.subscribe(List.of(TOPIC_NAME));

  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    for (ConsumerRecord<String, String> record : records) {
        log.info("{}", record);
    }
    consumer.commitSync();
  }
}
```
> `poll` 로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋하기 때문에 모든 레코드 처리가 끝난후 `commitSync` 호출

```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
  Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();

  for (ConsumerRecord<String, String> record : records) {
    log.info("{}", record);
    currentOffset.put(
            new TopicPartition(record.topic(), record.partition()),
            new OffsetAndMetadata(record.offset() + 1, null)
    );
    consumer.commitSync(currentOffset);    
  }
}
```
> `commitSync` 에 `TopicPartition` 과 `OffsetAndMetadata` 로 이루어진 map 을 파라미터로 넣어 호출하면 해당 특정 토픽, 파티션의 오프셋이 매번 커밋

### 비동기 오프셋 커밋
```java
while (true) {
  ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

  for (ConsumerRecord<String, String> record : records) {
    log.info("{}", record);
  }
  consumer.commitAsync();
}
```
> 비동기 오프셋 커밋도 `poll` 로 받은 가장 마지막 레코드의 오프셋을 기준으로 커밋하지만, 커밋이 완료될 때까지 기다리지 않는다

```java
 consumer.commitAsync((offsets, e) -> {
    if (e != null) {
        log.error("Commit failed for offsets {}", offsets, e);
    } else {
        log.info("Commit succeeded");
    }
});
```
> callback 을 정의할 수 있다

### 리밸런스 리스너를 가진 컨슈머
- 리밸런스 발생 시 데이터를 중복 처리하지 않게 하기 위해서는 리밸런스 발생 시 처리한 데이터를 기준으로 커밋을 시도해야 함
- `ConsumerRebalanceListener` : 리밸런스 발생 감지
  - `onPartitionRevoked()` : 리밸런스가 시작되기 직전 호출
  - `onPartitionAssigned()` : 리밸런스가 끝난 뒤에 파티션이 할당 완료되면 호출

### 파티션 할당 컨슈머
- `aasign()` 메서드를 이용하여 직접 파티션을 컨슈머에 할당하여 운영할 수도 있다

> `TopicPartition` 클래스는 카프카 라이브러리 내/외부에서 사용하는 토픽, 파티션의 정보를 담는 객체로 사용

### 컨슈머의 안정한 종료
- 정상적으로 종료되지 않은 컨슈머는 세션 타임아웃 전까지 컨슈머 그룹에 남게 됨
  - 컨슈머를 안전하게 종료하기 위해 `KafkaConsumer` 클래스는 `wakeup()` 메서드 지원
  - `wakeup()` 메서드 실행후 `poll()` 호출되면 `WakeupException` 발생
- 자바 애플리케이션은 코드 내부에 셧다운 훅(shutdown hook)을 구현하여 안정한 종료를 명시적으로 구현 
  - 하드웨어 이상으로 인한 종료는 어쩔 수 없음
  ```java
  public static void main(String[] args) {
    Runtime.getRuntime().addShutdownHook(new ShutdownThread());
    // ...
  }

  static class ShutdownThread extends Thread {
    public void run() {
        log.info("Shutdown hook");
        consumer.wakeup();
    }
  }
  ```

> shutdown hook : 운영체제로부터 용청을 받으면 실행하는 스레드

## 어드민 API
내부 옵션을 설정/조회하기 위한 API
```java
AdminClient admin = AdminClient.create(configs);
```

주요 메서드
|메서드명|설명|
|--|--|
|describeCluster(DescribeClusterOptions options)|브로커의 정보 조회|
|listTopics(ListTopicsOptions options)|토픽 리스트 조회|
|listConsumerGroups(ListConsumerGroupsOptions options)|컨슈머 그룹 조회|
|createTopics(Collection<NewTopic> newTopics, CreateTopicsOptions options)|신규 토픽 생성|
|createPartitions(Map<String, NewPartitions> newPartitions, CreatePartitionsOptions options)|파티션 개수 변경|
|createAcls(Collections<AclBinding> acls, CreateAclsOptions options)|접근 제어 규칙 생성|

# 카프카 스트림즈
- 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리
- 정확히 한번(exactly once)을 수행할 수 있게 장애 허용 시스템을 가지고 있어 데이터 처리 안정성이 뛰어남
- 프로듀서와 컨슈머를 조합하여 카프카 스트림즈가 제공하는 기능과 유사하게 만들 수 있다
  - 그러나 카프카 스트림즈의 기능들을 완벽히 구현해내기가 어렵기 때문에 카프카 스트림즈가 지원하지 않는 기능을 구현할 때 프로듀서와 컨슈머를 조합하여 사용하는 것이 좋다
- 스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있고, 스레드는 1개 이상의 태스크를 가짐
  - 태스크(task) : 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위
    - 파티션 개수 = task 개수
  - 병렬 처리를 위해 파티션과 스트림즈 스레드(또는 프로세스) 개수를 늘려 처리량을 늘릴 수 있음
- 운영 환경에서는 2개 이상의 스트림즈 애플리케이션 서버로 구성
- 토폴로지(topology) : 2개 이상의 노드들과 선으로 이루어진 집합 (ring, tree, star)
  - 프로세서(processor) : 토폴로지를 이루는 노드
    - `source processor` : 데이터를 처리하기 위해 최초로 선언해야 하는 노드, 하나 이상의 토픽에서 데이터를 가져오는 역할
    - `stream processor` : 다른 프로세서가 반환한 데이터를 처리하는 역할
    - `sink processor` : 데이터를 특정 카프카 토픽으로 저장, 스트림즈로 처리된 데이터의 최종 종착지
  - 스트림(stream) : 노드와 노드를 이은 선, 토픽의 데이터, 프로듀서와 컨슈머에서 활용했던 레코드와 동일
- `스트림즈DSL`과 `프로세서 API`의 2가지 방법으로 개발 가능
  - `스트림즈DSL`로 구현하는 데이터 처리 예시
    - 메시지 값을 기반으로 토픽 분기처리
    - 지난 10분간 들어온 데이터의 개수 집계
    - 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
  - `프로세서 API`로 구현하는 데이터 처리 예시
    - 메시지 값의 종류에 따라 토픽을 가변적으로 전송
    - 일정한 시간 간격으로 데이터 처리

## 스트림즈DSL
### KStream
- 레코드의 흐름을 표헌한 것
- 메시지 키와 메시지 값으로 구성
- 데이터를 조회하면 토픽에 존재하는(또는 `KStream`에 존재하는) 모든 레코드 출력
- 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있음

### KTable
- 메시지를 키를 기준으로 묶어서 사용
- 유니크한 메시지 키를 기준으로 가장 최신 레코드 사용
  - 메시지 키를 기준으로 가장 최신에 추가된 레코드의 데이터 출력
- 토픽은 1개 파티션이 1개 태스크에 할당되어 사용

### GlobalKTable
- 메시지 키를 기준으로 묶어서 사용
- 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용
  - 모든 태스크에 모든 데이터가 저장되고 사용되기 때문에 로컬 스토리지 사용량이 증가하고 네트워크, 브로커에 부하 발생
  - 되도록 작은 용량의 데이터에만 사용

### 코파티셔닝(co-partitioning)
- 코파티셔닝 : 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝 전략(`partitioning strategy`)을 동일하게 맞추는 작업
  - 파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장
- `KStream`과 `KTable`을 조인하려면 반드시 코파티셔닝 되어 있어야 함
  - 조인을 수행하려는 토픽들이 코파티셔닝 되어 있음을 보장할 수 없음
  - 2개의 토픽이 파티션 개수가 다를 수 있고, 파티션 전략이 다를 수 있음
  - 코파티셔닝 되지 않은 2개의 토픽을 조인하려고 하면 `TopologyException` 발생
  - 리파티셔닝(repartitioning) : 새로운 토픽에 새로운 메시지 키를 가지도록 배열
    - 리파티셔닝 과정을 거쳐 `KStream` 토픽과 `KTable` 토픽이 코파티셔닝 되도록 할 수 있다
- 조인되지 않은 `KStream`과 `KTable`을 조인해서 사용하고 싶다면 `KTable`을 `GlobalKTable`로 선언하여 사용
  - `GlobalKTable`은 코파티셔닝 되지 않은 `KStream`과 조인 가능 => `GlobalKTable`로 정의된 데이터는 모든 태스크에 동일하게 공유되기 때문

### 필수 옵션
- bootstrap.servers : 브로커의 호스트
- application.id : 스트림즈 애플리케이션을 구분하기 위한 고유한 아이디 설정, 다른 로직을 가진 애플리케이션들은 서로 다른 값을 가져야 함

### 선택 옵션
- default.key.serde : 레코드의 메시지 키를 직력화/역직렬화 하는 클래스 지정(기본값 : Sereds.ByteArray().getClass().getName())
- default.value.serde : 레코드의 메시지 값을 직력화/역직렬화 하는 클래스 지정(기본값 : Sereds.ByteArray().getClass().getName())
- num.stream.threads : 스트림 프로세싱 실행 시 실행될 스레드 개수 지정(기본값 : 1)
- state.dir : 상태기반 데이터 처리 시 데이터를 저장할 디렉터리 지정(기본값 : `/tmp/kafka-streams`)

### 스트림즈DSL - stream(), to()
- `stream()` : `KStream` 객체를 만든다. 최초의 토픽 데이터를 가져오는 `source processor`
  - `table()` : `KTable` 객체를 만든다
  - `globalTable()` : `GlobalKTable` 객체를 만든다
- `to()` : 데이터들을 특정 토픽으로 저장하기 위한 용도로 사용, `sink processor`
- `start()` : `KafkaStreams` 인스턴스 실행

### 스트림즈DSL - filter()
- `filter()` : `Predicate` 를 파라미터로 받아 데이터를 필터, `stream processor`

### 스트림즈DSL - join()
- `KTable`과 `KStream`을 조인할 때 가장 중요한 것은 코파티셔닝이 되어 있는 지 확인 하는 것
  - 메시지 키로 조인한다
- `GlobalKTable`과 `KStream`은 조인할 때 메시지 키와 값 모두 사용 가능
  - `KStream`의 메시지 값을 `GlobalKTable`의 메시지 키와 조인 가능
- `GlobalKTable`로 선언한 토픽은 존재하는 모든 데이터를 태스크마다 저장하고 조인 처리를 수행

> `KTable` 등을 사용하는 토픽이라고 특별한 것은 아님. 스트림즈 애플리케이션 내부에서 사용할 때 메시지 키와 메시지 값을 사용하는 형태를 구분할 뿐이다.

## 프로세서 API
- 스트림즈DSL 에서 사용했던 `KStream`, `KTable`, `GlobalKTable`의 개념이 없음
- 스트림 프로세서 클래스를 생성하기 위해서는 `kafka-stream` 라이브러리에서 제공하는 `Processor` 인터페이스를 구현해야 함

# 생각해볼 것
- 스트림즈DSL 을 쓰게 되면 파티션 개수를 증가 시키는 것에 대해 제약이 심해질 것 같다.
