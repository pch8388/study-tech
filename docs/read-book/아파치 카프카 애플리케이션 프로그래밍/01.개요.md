# 카프카의 탄생
- 기존의 데이터 파이프라인은 커플링이 심하여 문제가 많았음
- 카프카는 이러한 의존성 타파
- FIFO 방식의 큐와 유사
- ByteArray 로 통신 : 자바에서 선언 가능한 모든 객체 지원

# 빅데이터 파이프라인에서 카프카의 역할
- 데이터 레이크(data lake) : 빅데이터를 저장하고 활용하기 위해서 데이터를 모두 모으는 것
- 카프카는 필터링되거나 패키지화 되지 않은 데이터 저장(row data)

## 카프카가 데이터 파이프 라인으로 적합한 이유
### 높은 처리량
- 프로듀서가 브로커로 데이터를 보낼 때와 컨슈머가 브로커로부터 데이터를 받을 때 모두 묶어서 전송
- 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배, 데이터 병렬 처리
  - 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 데이터 처리량을 늘림

### 확장성
- 브로커 개수를 자연스럽게 늘려 스케일 아웃, 브로커 개수를 자연스럽게 줄여 스케일 인
- 스케일 아웃, 스케일 인 과정은 클러스트의 무중단 운영을 지원

### 영속성
- 데이터를 메모리에 저장하지 않고 파일 시스템에 저장
- 운영체제 레벨에서 파일 시스템을 최대한 활용하는 방법을 적용하여 속도 저하를 막음
  - 운영체제에서는 파일 I/O 성능 향상을 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용
  - 페이지 캐시 메모리 영역을 사용하여 한번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용하는 방식

### 고가용성
- 데이터의 복제(replication)
- 3대 이상의 브로커로 구성하는 것이 좋음

# 데이터 레이크 아키텍처와 카프카의 미래
## 레거시 데이터 플랫폼 아키텍처
logs -> 원천 데이터 -> 파생 데이터 -> 서빙 데이터 -> 엔드 유저

## 람다 아키텍처
logs -> 배치 레이어 / 스피드 레이어 -> 서빙 레이어 -> 엔드 유저  
logs -> 스피드 레이어 -> 엔드 유저

- 서빙 레이어(serving layer) : 가공된 데이터를 데이터 사용자 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간
- 스피드 레이어(speed layer) : 서비스에서 생성되는 원천 데이터를 실시간으로 분석하는 용도 => 카프카가 위치하는 곳
- 레이어가 2개로 나뉘기 때문에 생기는 단점이 있음
  - 로직의 파편화, 디버깅, 배포, 운영 분리 이슈

## 카파 아키텍처
logs -> 스피드 레이어 -> 서빙 레이어 -> 엔드 유저

> 배치 데이터 : 초, 분 시간, 일 등으로 한정된(bounded) 기간 단위 데이터  
> 스트림 데이터 : 한정되지 않은(unbounded) 데이터. 시작 데이터와 끝 데이터가 명확히 정해지지 않은 데이터

> 로그는 배치 데이터를 스트림으로 표현하기에 적합

## 스트리밍 데이터 레이크 아키텍처
logs -> 스피드 레이어 -> 엔드 유저

- 스피드 레이어에서 데이터를 분석, 프로세싱, 저장함으로써 단일 진실 공급원(SSOT, Single Source OF Truth)이 된다