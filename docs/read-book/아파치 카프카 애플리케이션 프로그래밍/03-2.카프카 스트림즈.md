# 카프카 스트림즈
- 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리
- 정확히 한번(exactly once)을 수행할 수 있게 장애 허용 시스템을 가지고 있어 데이터 처리 안정성이 뛰어남
- 프로듀서와 컨슈머를 조합하여 카프카 스트림즈가 제공하는 기능과 유사하게 만들 수 있다
  - 그러나 카프카 스트림즈의 기능들을 완벽히 구현해내기가 어렵기 때문에 카프카 스트림즈가 지원하지 않는 기능을 구현할 때 프로듀서와 컨슈머를 조합하여 사용하는 것이 좋다
- 스트림즈 애플리케이션은 내부적으로 스레드를 1개 이상 생성할 수 있고, 스레드는 1개 이상의 태스크를 가짐
  - 태스크(task) : 스트림즈 애플리케이션을 실행하면 생기는 데이터 처리 최소 단위
    - 파티션 개수 = task 개수
  - 병렬 처리를 위해 파티션과 스트림즈 스레드(또는 프로세스) 개수를 늘려 처리량을 늘릴 수 있음
- 운영 환경에서는 2개 이상의 스트림즈 애플리케이션 서버로 구성
- 토폴로지(topology) : 2개 이상의 노드들과 선으로 이루어진 집합 (ring, tree, star)
  - 프로세서(processor) : 토폴로지를 이루는 노드
    - `source processor` : 데이터를 처리하기 위해 최초로 선언해야 하는 노드, 하나 이상의 토픽에서 데이터를 가져오는 역할
    - `stream processor` : 다른 프로세서가 반환한 데이터를 처리하는 역할
    - `sink processor` : 데이터를 특정 카프카 토픽으로 저장, 스트림즈로 처리된 데이터의 최종 종착지
  - 스트림(stream) : 노드와 노드를 이은 선, 토픽의 데이터, 프로듀서와 컨슈머에서 활용했던 레코드와 동일
- `스트림즈DSL`과 `프로세서 API`의 2가지 방법으로 개발 가능
  - `스트림즈DSL`로 구현하는 데이터 처리 예시
    - 메시지 값을 기반으로 토픽 분기처리
    - 지난 10분간 들어온 데이터의 개수 집계
    - 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
  - `프로세서 API`로 구현하는 데이터 처리 예시
    - 메시지 값의 종류에 따라 토픽을 가변적으로 전송
    - 일정한 시간 간격으로 데이터 처리

## 스트림즈DSL
### KStream
- 레코드의 흐름을 표헌한 것
- 메시지 키와 메시지 값으로 구성
- 데이터를 조회하면 토픽에 존재하는(또는 `KStream`에 존재하는) 모든 레코드 출력
- 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있음

### KTable
- 메시지를 키를 기준으로 묶어서 사용
- 유니크한 메시지 키를 기준으로 가장 최신 레코드 사용
  - 메시지 키를 기준으로 가장 최신에 추가된 레코드의 데이터 출력
- 토픽은 1개 파티션이 1개 태스크에 할당되어 사용

### GlobalKTable
- 메시지 키를 기준으로 묶어서 사용
- 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용
  - 모든 태스크에 모든 데이터가 저장되고 사용되기 때문에 로컬 스토리지 사용량이 증가하고 네트워크, 브로커에 부하 발생
  - 되도록 작은 용량의 데이터에만 사용

### 코파티셔닝(co-partitioning)
- 코파티셔닝 : 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝 전략(`partitioning strategy`)을 동일하게 맞추는 작업
  - 파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장
- `KStream`과 `KTable`을 조인하려면 반드시 코파티셔닝 되어 있어야 함
  - 조인을 수행하려는 토픽들이 코파티셔닝 되어 있음을 보장할 수 없음
  - 2개의 토픽이 파티션 개수가 다를 수 있고, 파티션 전략이 다를 수 있음
  - 코파티셔닝 되지 않은 2개의 토픽을 조인하려고 하면 `TopologyException` 발생
  - 리파티셔닝(repartitioning) : 새로운 토픽에 새로운 메시지 키를 가지도록 배열
    - 리파티셔닝 과정을 거쳐 `KStream` 토픽과 `KTable` 토픽이 코파티셔닝 되도록 할 수 있다
- 조인되지 않은 `KStream`과 `KTable`을 조인해서 사용하고 싶다면 `KTable`을 `GlobalKTable`로 선언하여 사용
  - `GlobalKTable`은 코파티셔닝 되지 않은 `KStream`과 조인 가능 => `GlobalKTable`로 정의된 데이터는 모든 태스크에 동일하게 공유되기 때문

### 필수 옵션
- bootstrap.servers : 브로커의 호스트
- application.id : 스트림즈 애플리케이션을 구분하기 위한 고유한 아이디 설정, 다른 로직을 가진 애플리케이션들은 서로 다른 값을 가져야 함

### 선택 옵션
- default.key.serde : 레코드의 메시지 키를 직력화/역직렬화 하는 클래스 지정(기본값 : Sereds.ByteArray().getClass().getName())
- default.value.serde : 레코드의 메시지 값을 직력화/역직렬화 하는 클래스 지정(기본값 : Sereds.ByteArray().getClass().getName())
- num.stream.threads : 스트림 프로세싱 실행 시 실행될 스레드 개수 지정(기본값 : 1)
- state.dir : 상태기반 데이터 처리 시 데이터를 저장할 디렉터리 지정(기본값 : `/tmp/kafka-streams`)

### 스트림즈DSL - stream(), to()
- `stream()` : `KStream` 객체를 만든다. 최초의 토픽 데이터를 가져오는 `source processor`
  - `table()` : `KTable` 객체를 만든다
  - `globalTable()` : `GlobalKTable` 객체를 만든다
- `to()` : 데이터들을 특정 토픽으로 저장하기 위한 용도로 사용, `sink processor`
- `start()` : `KafkaStreams` 인스턴스 실행

### 스트림즈DSL - filter()
- `filter()` : `Predicate` 를 파라미터로 받아 데이터를 필터, `stream processor`

### 스트림즈DSL - join()
- `KTable`과 `KStream`을 조인할 때 가장 중요한 것은 코파티셔닝이 되어 있는 지 확인 하는 것
  - 메시지 키로 조인한다
- `GlobalKTable`과 `KStream`은 조인할 때 메시지 키와 값 모두 사용 가능
  - `KStream`의 메시지 값을 `GlobalKTable`의 메시지 키와 조인 가능
- `GlobalKTable`로 선언한 토픽은 존재하는 모든 데이터를 태스크마다 저장하고 조인 처리를 수행

> `KTable` 등을 사용하는 토픽이라고 특별한 것은 아님. 스트림즈 애플리케이션 내부에서 사용할 때 메시지 키와 메시지 값을 사용하는 형태를 구분할 뿐이다.

## 프로세서 API
- 스트림즈DSL 에서 사용했던 `KStream`, `KTable`, `GlobalKTable`의 개념이 없음
- 스트림 프로세서 클래스를 생성하기 위해서는 `kafka-stream` 라이브러리에서 제공하는 `Processor` 인터페이스를 구현해야 함

# 생각해볼 것
- 스트림즈DSL 을 쓰게 되면 파티션 개수를 증가 시키는 것에 대해 제약이 심해질 것 같다.
- DefaultPartitioner 를 사용하면 StickyPartitionCache 의 구현을 내부에서 사용하는데, 이것만 라운드 로빈 방식으로 바꾸는 방법도 있을까?