# AWS 인스턴스 생성
OS 이미지 선택
<img width="761" alt="스크린샷 2022-06-13 오전 11 24 24" src="https://user-images.githubusercontent.com/17218212/173269756-4130d10d-49e5-47d6-8fc2-add1f56496dc.png">

인스턴스 유형 선택
<img width="750" alt="스크린샷 2022-06-13 오전 11 24 31" src="https://user-images.githubusercontent.com/17218212/173269775-1dbad3c0-f760-4204-bb19-6708be82cf85.png">

키페어 생성
<img width="729" alt="스크린샷 2022-06-13 오전 11 24 36" src="https://user-images.githubusercontent.com/17218212/173269778-6da6db11-e0f8-4e6d-86d5-c48dcf0b62da.png">

인바운드 규칙 설정
- 카프카 브로커 : 9092
- 주키퍼 : 2181
<img width="1409" alt="스크린샷 2022-06-13 오전 11 34 09" src="https://user-images.githubusercontent.com/17218212/173269780-61721ebe-476e-4395-9c7f-8dc7412f6c6c.png">

# 인스턴스에 접속
## ssh 명령어로 접속
생성한 키페어는 read 권한만 있어야 하기 때문에 권한을 변경
```bash
chmod 400 kafka-study.pem
```

ssh 접속
```bash
ssh -i kafka-study.pem <유저id>@<퍼블릭IP>
```

## java 설치
카프카 브로커 실행을 위해 java 설치 필요
```bash
sudo yum install -y java-1.8.0-openjdk-devel.x86_64

# 제대로 설치되었는지 버전 확인
java -version 
```

## 주키퍼, 카프카 브로커 실행
카프카 [다운로드](https://kafka.apache.org/downloads) 링크에서 다운로드 링크를 복사해서 wget 명령어로 다운받는다
```bash
wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz

# 압축 해제
tar xvf kafka_2.12-2.5.0.tgz

cd kafka_2.12-2.5.0/
```

> 카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메모리 사용하고, 나머지 객체는 힙 메모리에 저장하여 사용하기 때문에 카프카 브로커 운영시 힙 메모리를 5GB 이상으로 설정하지 않는 것이 일반적이다

### 카프카 힙메모리 설정
```bash
export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
echo $KAFKA_HEAP_OPTS
```

- kafka-server-start.sh 에서 시작 스크립트 확인 가능

### 카프카 브로커 실행 옵션 설정
`config/server.properties` 파일에 카프카 브로커가 클러스터 운영에 필요한 옵션들 지정
- advertised.listener : 카프카 클라이언트 또는 커맨드 라인 툴을 브로커와 연결할 때 사용
  - `advertised.listener=PLAINTEXT://퍼블릭IP:9092`
- 이미 실행되고 있는 카프카 브로커의 설정을 변경하려면 브로커를 재시작해야 함

|옵션이름|설명|
|--|--|
|broker.id|카프카 브로커 ID|
|listeners|카프카 브로커가 통신을 위해 열어둘 인터페이스 IP, port, 프로토콜 설정|
|advertised.listeners|카프카 클라이언트나 커맨드 라인 툴에서 접속할때 사용하는 IP, port 정보|
|listener.security.protocol.map|SASL_SSL, SASL_PLAIN 보안 설정 시 프로토콜 매핑 설정|
|num.network.threads|네트워크 스레드 개수 설정|
|num.io.threads|카프카 브로커 내부에서 사용할 스레드 개수|
|log.dirs|통신을 통해 가져온 데이터를 파일로 저장할 디렉터리 위치, 브로커 실행전에 생성이 되어 있어야 함|
|num.partitions|파티션 개수를 명시하지 않고 토픽 생성 시 기본 설정되는 파티션 개수|
|log.retention.hours|브로커가 저장한 파일이 삭제되기까지 걸리는 시간. log.retention.ms로 값을 지정하여 설정하는 것을 추천. -1로 지정하면 영원히 삭제되지 않음|
|log.segment.bytes|브로커가 저장할 파일의 최대 크기 지정. 여기서 설정한 크기를 넘게 되면 새로운 파일이 생성됨|
|log.retention.check.interval.ms|브로커가 저장한 파일을 삭제하기 위해 체크하는 간격 지정|
|zookeeper.connect|브로커와 연동할 주키퍼의 IP, port 설정|
|zookeeper.connection.timeout.ms|주키퍼의 세션 타임아웃 시간|

### 주키퍼 실행
- 주키퍼는 카프카의 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있음
- 상용환경에서 안전하게 운영하기 위해서는 3대 이상의 서버로 구성해서 사용
- `-daemon` 옵션과 주키퍼 설정 경로인 `config/zookeeper.proerteis`와 함께 주키퍼 시작 스크립트인 `bin/zookeeper-server-start.sh`를 실행하면 주키퍼를 백그라운드에서 실행할 수 있다
  - jps 명령어로 실행된 것 확인
    - jps : JVM 프로세스 상태를 보는 도구. `-m` 옵션 : main 메서드에 전달된 인자 확인. `-v` 옵션 : JVM 에 전달된 인자 확인

```bash
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
jps -vm
```

### 카프카 브로커 실행 및 로그 확인
- `kafka-server-start.sh` 실행하여 브로커 실행
  - `-daemon` 옵션을 사용하여 카프카 브로커가 백그라운드로 실행되게 할 수 있다
  - jps 명령어로 실행 확인
  - tail 명령어로 로그 확인

```bash
bin/kafka-server-start.sh -daemon config/server.properties
jps -m
tail -f logs/server.log
```

## 로컬에서 카프카 서버 통신 확인
로컬에 카프카 설치 후 실행
```bash
wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz

# 압축 해제
tar xvf kafka_2.12-2.5.0.tgz

cd kafka_2.12-2.5.0/

bin/kafka-broker-api-versions.sh --bootstrap-server 인스턴스IP:9092
```
> 카프카 브로커와 로컬 커맨드 라인 툴의 버전은 맞춰야 함

# 카프카 커맨드 라인 툴
커맨드 라인 툴을 사용할 때 필수 옵션과 선택 옵션이 있는 데, 선택 옵션은 입력하지 않을 시 기본 값으로 명령이 실행됨 => 항상 옵션을 체크하고 명령을 수행해야 안전

## kafka-topics.sh
토픽과 관련된 명령어 실행
> 토픽은 브로커에 생성되지 않은 상태에서 메시지를 보내서 생성하는 방법과 명시적인 명령으로 생성하도록 하는 방법이 있다

### 토픽 생성
```bash
$ bin/kafka-topics.sh \
  --create \                            # 토픽 생성하는 명령 옵션
  --bootstrap-server my-kafka:9092 \    # 토픽을 생성할 카프카 클러스터를 구성하는 브로커들의 ip, port
  --topic hello.kafka                   # 토픽 이름
```

```bash
$ bin/kafka-topics.sh \
  --create \
  --bootstrap-server my-kafka:9092 \
  --partitions 3 \                      # 파티션 개수 지정 (최소 1개) => 옵션 미사용시 num.partitions 값 사용
  --replication-factor 1 \              # 파티션을 복제할 복제 개수 (1이면 복제하지 않음, 2이면 1개 복제) => 브로커로 복제
  --config retention.ms=172800000 \     # config 로 kafka-topics.sh 에 포함되지 않은 옵션도 설정할 수 있음
  --topic hello.kafka.2
```

### 토픽 리스트 조회
```bash
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
```

### 토픽 상세 조회
```bash
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2

# 조회시 나오는 Leader 의 값이 현재 파티션의 리더가 어떤 브로커에 위치하는 지 브로커 ID 를 보여준다
```
> 리더 파티션이 일부 브로커로 몰려 있을 경우 부하가 쏠릴 가능성이 있음

### 토픽 옵션 수정
`kafka-topics.sh` 과 `kafka-configs.sh` 를 사용하여 설정을 변경하는 데, 변경할 수 있는 항목이 다르다

```bash
# 파티션 4개로 변경
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 \
  --topic hello.kafka \
  --alter \
  --partitions 4

# 확인
$ bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka

# retention.ms 수정
$ bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
  --entity-type topics \
  --entity-name hello.kafka \
  --alter --add-config retention.ms=86400000

# 확인
$ bin/kafka-configs.sh --bootstrap-server my-kafka:9092 \
  --entity-type topics \
  --entity-name hello.kafka \
  --describe
```

## kafka-console-producer.sh
토픽에 데이터를 넣음
- 토픽에 넣는 데이터는 record 라고 부르며 key, value 로 이루어져 있음
  - 메시지 키 없이 값만 보내면 자바의 null 로 기본 설정되어 브로커로 전송됨
    ```bash
    $ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
      --topic hello.kafka
      # 메시지 입력
      >hello
      >kafka
    ```
- key:value 형태로 전송하기
```bash
$ bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 \
  --topic hello.kafka \
  --property "parse.key=true" \  # parse.key 가 true 이면 레코드를 전송할 때 메시지 키를 추가할 수 있다
  --property "key.separator=:"   # 설정하지 않으면 기본은 \t
  # 메시지 입력
  >key1:no1
  >key2:no2
```

- `kafka-console-producer.sh`로 전송되는 레코드 값은 UTF-8 기반 Byte 로 변환되고 `ByteArraySerializer` 로만 직렬화 되기 때문에 String 타입으로만 직렬화 가능
- 키가 null 인 레코드는 라운드 로빈 방식으로 파티션에 할당
- 키가 존재하는 리코드는 키의 해시값을 작성하여 존재하는 파티션 중 하나에 할당되고 같은 키라면 항상 같은 파티션에 할당 된다
  - 파티션 개수가 늘어나면 새로 프로듀싱 되는 레코드는 다른 파티션에 할당될 수 있다. 커스텀 파티셔너를 만들어서 운영하여 이 문제를 해결한다

